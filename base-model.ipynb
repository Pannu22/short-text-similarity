{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4665</td>\n",
       "      <td>do you accept broadband bills</td>\n",
       "      <td>Broadband bill</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>26465</td>\n",
       "      <td>I am getting better fare for this flight</td>\n",
       "      <td>Check flight rate</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>57679</td>\n",
       "      <td>Flight from delhi to srinagar</td>\n",
       "      <td>check price for flight from mumbai to pune</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>22043</td>\n",
       "      <td>Availability of food</td>\n",
       "      <td>food available for guest</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6522</td>\n",
       "      <td>This is my ID only</td>\n",
       "      <td>Can't find order ID.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pid                                 sentence1  \\\n",
       "0   4665             do you accept broadband bills   \n",
       "1  26465  I am getting better fare for this flight   \n",
       "2  57679             Flight from delhi to srinagar   \n",
       "3  22043                      Availability of food   \n",
       "4   6522                        This is my ID only   \n",
       "\n",
       "                                    sentence2  label  \n",
       "0                              Broadband bill      1  \n",
       "1                           Check flight rate      0  \n",
       "2  check price for flight from mumbai to pune      1  \n",
       "3                    food available for guest      1  \n",
       "4                        Can't find order ID.      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"../short-text-similarity/data/train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(sent):\n",
    "    sent = sent.lower()\n",
    "    stop_words = list(punctuation)\n",
    "    tokens = word_tokenize(sent)\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    stemmer = PorterStemmer()\n",
    "    stem_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    sent = ' '.join(stem_tokens)\n",
    "    \n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_sentence1'] = data['sentence1'].apply(cleaner)\n",
    "data['clean_sentence2'] = data['sentence2'].apply(cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[['clean_sentence1', 'clean_sentence2']], data['label'], \n",
    "                                                    test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_sent1 = TfidfVectorizer()\n",
    "tfidf_sent2 = TfidfVectorizer()\n",
    "tfidf_vect_sent1_train = tfidf_sent1.fit_transform(X_train['clean_sentence1'])\n",
    "tfidf_vect_sent2_train = tfidf_sent2.fit_transform(X_train['clean_sentence2'])\n",
    "tfidf_vect_train = np.concatenate([tfidf_vect_sent1_train.toarray(), tfidf_vect_sent2_train.toarray()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Tf-Idf vector of sentence1 : (11419, 1877)\n",
      "Shape of Tf-Idf vector of sentence2 : (11419, 1916)\n",
      "Shape of Tf-Idf vector of cobination of both sentences : (11419, 3793)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Tf-Idf vector of sentence1 :', tfidf_vect_sent1_train.toarray().shape)\n",
    "print('Shape of Tf-Idf vector of sentence2 :', tfidf_vect_sent2_train.toarray().shape)\n",
    "print('Shape of Tf-Idf vector of cobination of both sentences :', tfidf_vect_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect_sent1_test = tfidf_sent1.transform(X_test['clean_sentence1'])\n",
    "tfidf_vect_sent2_test = tfidf_sent2.transform(X_test['clean_sentence2'])\n",
    "tfidf_vect_test = np.concatenate([tfidf_vect_sent1_test.toarray(), tfidf_vect_sent2_test.toarray()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Tf-Idf vector of sentence1 : (5625, 1877)\n",
      "Shape of Tf-Idf vector of sentence2 : (5625, 1916)\n",
      "Shape of Tf-Idf vector of cobination of both sentences : (5625, 3793)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Tf-Idf vector of sentence1 :', tfidf_vect_sent1_test.toarray().shape)\n",
    "print('Shape of Tf-Idf vector of sentence2 :', tfidf_vect_sent2_test.toarray().shape)\n",
    "print('Shape of Tf-Idf vector of cobination of both sentences :', tfidf_vect_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pannu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 570 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log_clf = LogisticRegression(random_state=0).fit(tfidf_vect_train, y_train)\n",
    "log_pred = log_clf.predict(tfidf_vect_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score using Logistic Regression : 0.8049446174714989\n",
      "Confusion Matrix using Logistic Regression :\n",
      "[[3974  211]\n",
      " [ 792  648]]\n"
     ]
    }
   ],
   "source": [
    "log_f1 = f1_score(y_test, log_pred, average='weighted')\n",
    "print('F1 score using Logistic Regression :', log_f1)\n",
    "print('Confusion Matrix using Logistic Regression :')\n",
    "print(confusion_matrix(y_test, log_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Logistic Regression on test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>54615</td>\n",
       "      <td>As an investor how do I avail benefit with res...</td>\n",
       "      <td>Stamp Duty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>53768</td>\n",
       "      <td>cash back nahi aaya</td>\n",
       "      <td>Muje cash back nahi mila</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>26567</td>\n",
       "      <td>LPG Storage Sytem Warranty</td>\n",
       "      <td>Is there any license required for LPG storage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4028</td>\n",
       "      <td>i want discount on flight tickets</td>\n",
       "      <td>I want discounts on train booking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5145</td>\n",
       "      <td>nearby bus stop</td>\n",
       "      <td>bus stop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pid                                          sentence1  \\\n",
       "0  54615  As an investor how do I avail benefit with res...   \n",
       "1  53768                                cash back nahi aaya   \n",
       "2  26567                         LPG Storage Sytem Warranty   \n",
       "3   4028                  i want discount on flight tickets   \n",
       "4   5145                                    nearby bus stop   \n",
       "\n",
       "                                           sentence2  \n",
       "0                                         Stamp Duty  \n",
       "1                           Muje cash back nahi mila  \n",
       "2  Is there any license required for LPG storage ...  \n",
       "3                  I want discounts on train booking  \n",
       "4                                           bus stop  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv(r\"../short-text-similarity/data/test.csv\")\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['clean_sentence1'] = data_test['sentence1'].apply(cleaner)\n",
    "data_test['clean_sentence2'] = data_test['sentence2'].apply(cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect_sent1_test_data = tfidf_sent1.transform(data_test['clean_sentence1'])\n",
    "tfidf_vect_sent2_test_data = tfidf_sent2.transform(data_test['clean_sentence2'])\n",
    "tfidf_vect_test_data = np.concatenate([tfidf_vect_sent1_test_data.toarray(), tfidf_vect_sent2_test_data.toarray()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Tf-Idf vector of sentence1 : (7305, 1877)\n",
      "Shape of Tf-Idf vector of sentence2 : (7305, 1916)\n",
      "Shape of Tf-Idf vector of cobination of both sentences : (7305, 3793)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Tf-Idf vector of sentence1 :', tfidf_vect_sent1_test_data.toarray().shape)\n",
    "print('Shape of Tf-Idf vector of sentence2 :', tfidf_vect_sent2_test_data.toarray().shape)\n",
    "print('Shape of Tf-Idf vector of cobination of both sentences :', tfidf_vect_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pred_test_data = log_clf.predict(tfidf_vect_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = pd.DataFrame(data = data_test['pid'], columns = ['pid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df['label'] = log_pred_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit_df.to_csv(r\"../short-text-similarity/output/base_logreg.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's built vectors considering context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_bigram_sent1 = TfidfVectorizer(ngram_range = (1, 2))\n",
    "tfidf_bigram_sent2 = TfidfVectorizer(ngram_range = (1, 2))\n",
    "tfidf_bigram_sent1_train = tfidf_bigram_sent1.fit_transform(X_train['clean_sentence1'])\n",
    "tfidf_bigram_sent2_train = tfidf_bigram_sent2.fit_transform(X_train['clean_sentence2'])\n",
    "tfidf_bigram_train = np.concatenate([tfidf_bigram_sent1_train.toarray(), tfidf_bigram_sent2_train.toarray()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Tf-Idf bigram vector of sentence1 : (11419, 9577)\n",
      "Shape of Tf-Idf bigram vector of sentence2 : (11419, 9878)\n",
      "Shape of Tf-Idf bigram vector of cobination of both sentences : (11419, 19455)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Tf-Idf bigram vector of sentence1 :', tfidf_bigram_sent1_train.toarray().shape)\n",
    "print('Shape of Tf-Idf bigram vector of sentence2 :', tfidf_bigram_sent2_train.toarray().shape)\n",
    "print('Shape of Tf-Idf bigram vector of cobination of both sentences :', tfidf_bigram_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_bigram_sent1_test = tfidf_bigram_sent1.transform(X_test['clean_sentence1'])\n",
    "tfidf_bigram_sent2_test = tfidf_bigram_sent2.transform(X_test['clean_sentence2'])\n",
    "tfidf_bigram_test = np.concatenate([tfidf_bigram_sent1_test.toarray(), tfidf_bigram_sent2_test.toarray()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Tf-Idf bigram vector of sentence1 : (5625, 9577)\n",
      "Shape of Tf-Idf bigram vector of sentence2 : (5625, 9878)\n",
      "Shape of Tf-Idf bigram vector of cobination of both sentences : (5625, 19455)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Tf-Idf bigram vector of sentence1 :', tfidf_bigram_sent1_test.toarray().shape)\n",
    "print('Shape of Tf-Idf bigram vector of sentence2 :', tfidf_bigram_sent2_test.toarray().shape)\n",
    "print('Shape of Tf-Idf bigram vector of cobination of both sentences :', tfidf_bigram_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pannu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log_clf_bigram = LogisticRegression(random_state=0).fit(tfidf_bigram_train, y_train)\n",
    "log_bigram_pred = log_clf_bigram.predict(tfidf_bigram_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score using Logistic Regression : 0.8332107531889804\n",
      "Confusion Matrix using Logistic Regression :\n",
      "[[4069  116]\n",
      " [ 735  705]]\n"
     ]
    }
   ],
   "source": [
    "log_f1 = f1_score(y_test, log_bigram_pred, average='weighted')\n",
    "print('F1 score using Logistic Regression :', log_f1)\n",
    "print('Confusion Matrix using Logistic Regression :')\n",
    "print(confusion_matrix(y_test, log_bigram_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After consider context (Bigram) we can see 3% boost in F1 Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "deci_clf_bigram = DecisionTreeClassifier(random_state=0).fit(tfidf_bigram_train, y_train)\n",
    "deci_bigram_pred = deci_clf_bigram.predict(tfidf_bigram_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score using Decision Tree Classifier : 0.8562878301322314\n",
      "Confusion Matrix using Decision Tree Classifier :\n",
      "[[3845  340]\n",
      " [ 457  983]]\n"
     ]
    }
   ],
   "source": [
    "deci_f1 = f1_score(y_test, deci_bigram_pred, average='weighted')\n",
    "print('F1 score using Decision Tree Classifier :', deci_f1)\n",
    "print('Confusion Matrix using Decision Tree Classifier :')\n",
    "print(confusion_matrix(y_test, deci_bigram_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's predict labels on Test Data using Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect_sent1_test_data = tfidf_bigram_sent1.transform(data_test['clean_sentence1'])\n",
    "tfidf_vect_sent2_test_data = tfidf_bigram_sent2.transform(data_test['clean_sentence2'])\n",
    "tfidf_vect_test_data = np.concatenate([tfidf_vect_sent1_test_data.toarray(), tfidf_vect_sent2_test_data.toarray()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Tf-Idf vector of sentence1 : (7305, 9577)\n",
      "Shape of Tf-Idf vector of sentence2 : (7305, 9878)\n",
      "Shape of Tf-Idf vector of cobination of both sentences : (7305, 19455)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Tf-Idf vector of sentence1 :', tfidf_vect_sent1_test_data.toarray().shape)\n",
    "print('Shape of Tf-Idf vector of sentence2 :', tfidf_vect_sent2_test_data.toarray().shape)\n",
    "print('Shape of Tf-Idf vector of cobination of both sentences :', tfidf_vect_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "deci_bigram_pred_test_data = deci_clf_bigram.predict(tfidf_vect_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = pd.DataFrame(data = data_test['pid'], columns = ['pid'])\n",
    "submit_df['label'] = deci_bigram_pred_test_data\n",
    "# submit_df.to_csv(r\"../short-text-similarity/output/deci_bigram.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_csv(r\"../short-text-similarity/data/clean_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cbot",
   "language": "python",
   "name": "cbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
